{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1b2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from decimal import *\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sobol\n",
    "import nbimporter\n",
    "from PINN_Solver_Classes import *\n",
    "from PDE_Classes import *\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "# from keras import callbacks\n",
    "# import time\n",
    "# import itertools as product\n",
    "\n",
    "# Set data type\n",
    "DTYPE = 'float64'\n",
    "tf.keras.backend.set_floatx(DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c55f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_b = 2**8 # number of boundary and interface points\n",
    "N_r = 2**10 # number of internal collocation points\n",
    "\n",
    "# Declare PDE parameters\n",
    "nu = 0.000001\n",
    "beta = 1\n",
    "\n",
    "if nu <= 2e-3:\n",
    "    mu = np.log(( (nu/beta)**(nu/beta) )*(np.exp(1)))\n",
    "else:\n",
    "    mu = (nu/beta)*np.log( ( nu/beta )*( np.exp(beta/nu) - 1 ) )\n",
    "\n",
    "# Declare bounds of each subdomain\n",
    "sub = (\n",
    "      [0, 0.7],\n",
    "      [0.6, 1]\n",
    "      )\n",
    "\n",
    "# Initialize list of points which lie on the boundary\n",
    "BC = [0, 1]\n",
    "\n",
    "# Lower bounds as TF scalars \n",
    "x0_om = tf.constant([x[0] for x in sub], dtype=DTYPE)\n",
    "# Upper bounds as TF scalars \n",
    "x1_om = tf.constant([x[1] for x in sub], dtype=DTYPE)\n",
    "\n",
    "# Generate boundary points for each subdomain boundary\n",
    "# zipped booleans indicate whether a point is a model or interface boundary\n",
    "X_b = tuple( zip( [tf.constant(np.repeat([[i]], N_b, axis=0), dtype=DTYPE) for i in sub[0]], [k in BC for k in sub[0]] ) ) \n",
    "\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Generate uniform internal points for the whole domain\n",
    "points = sobol.sample(dimension=1, n_points=N_r-2)\n",
    "xwidth = BC[1] - BC[0]\n",
    "x_uni = np.vstack( (np.vstack( ([0], xwidth*points + BC[0]) ), [1]) )\n",
    "\n",
    "# # Generate internal points with gaussian distribution centered at the shock\n",
    "# sigma = (x1_om[-1] - x0_om[0])/2\n",
    "# x_gauss = np.array(stats.truncnorm((x0_om[0] - mu) / sigma, (x1_om[-1] - mu) / sigma, loc=mu, scale=sigma).rvs(N_r))\n",
    "\n",
    "# # Take as the final sample set the union of the two sets defined above\n",
    "# x = np.union1d(x_uni, x_gauss)\n",
    "\n",
    "# Store internal points as tensor object\n",
    "X = tf.constant(x_uni, shape=(len(x_uni), 1), dtype=DTYPE)\n",
    "\n",
    "# Split internal points by subdomain and store in tuple\n",
    "mask = (X >= x0_om[0]) & (X <= x1_om[0])\n",
    "temp = tf.boolean_mask(X, mask)\n",
    "X_r = tf.constant(temp, shape=(temp.shape[0],1), dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare PDE first as a class for the PINN solver to inherit\n",
    "pde = PDE_1D_Steady_AdvecDiff\n",
    "\n",
    "# Then declare an instance of the PDE class to use in the Driver\n",
    "order = 2\n",
    "pde1 = pde(nu=nu, beta=beta, order=order)\n",
    "\n",
    "X_om = [tf.constant(np.linspace(s[0], s[1], num=N_r), shape=(N_r, 1), dtype=DTYPE) for s in sub]\n",
    "\n",
    "xl = sub[-1][0]\n",
    "xr = sub[-1][1]\n",
    "\n",
    "x_FD = X_om[1]\n",
    "\n",
    "print(tf.reshape(x_FD[0], shape=(1,1)))\n",
    "\n",
    "h = x_FD[1] - x_FD[0]\n",
    "\n",
    "a = - nu/(h**2)\n",
    "b = (2*nu)/(h**2)\n",
    "c = -(nu/(h**2))\n",
    "\n",
    "if order == 1:\n",
    "    b += beta / h\n",
    "    c += -beta / h\n",
    "    d = 0.0\n",
    "elif order == 2:\n",
    "    b += 3 / 2 * beta / h\n",
    "    c += -2 * beta / h\n",
    "    d = 1 / 2 * beta / h\n",
    "\n",
    "A = np.diagflat([b]*(N_r-1)) + np.diagflat([c]*(N_r - 2), -1) + np.diagflat([a]*(N_r - 2), 1) + np.diagflat([d]*(N_r - 3), -2)\n",
    "\n",
    "f = np.ones((N_r-1, 1))\n",
    "\n",
    "f[0] += -d*np.random.rand(1) - c*np.random.rand(1)\n",
    "f[1] += -d*np.random.rand(1)\n",
    "#f[-1] += -a*pde1.f(xr) \n",
    "\n",
    "u_FD = np.linalg.solve( A, f )\n",
    "\n",
    "u_FD = np.hstack((u_FD.flatten(), pde1.f(xr)))\n",
    "\n",
    "u_int = np.interp(x1_om[0], x_FD[:,0], u_FD)\n",
    "\n",
    "\n",
    "# x_true = np.linspace(0, 1, num=5001)\n",
    "# u_true = pde1.f(x_true)\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,4), dpi=600)\n",
    "\n",
    "# ax.plot(x_true, u_true, 'b-', x_FD, u_FD, 'r-')\n",
    "# ax.set_xlabel('x', fontsize=18)\n",
    "# ax.set_ylabel('u(x)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5cdd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network to handle each domain and intialize data frame for loss\n",
    "column_list = []\n",
    "model_r = PINN_Architecture(x0_om[0], x1_om[0])\n",
    "model_r.build(input_shape=(None, X_r.shape[1]))\n",
    "\n",
    "for i in range(len(sub)):\n",
    "    column_list += [\"model {:d} Phi_r\".format(i+1), \n",
    "                    \"model {:d} Phi_i\".format(i+1), \"model {:d} Loss\".format(i+1)]\n",
    "\n",
    "loss_frame = pd.DataFrame(columns=column_list)\n",
    "\n",
    "# Define learning rate schedule and choose optimizer (Adam)\n",
    "lr = 1e-3 #tf.keras.optimizers.schedules.PiecewiseConstantDecay([2**6, 2**7],[1e-2,5e-3,1e-3])\n",
    "\n",
    "# Declare hyperparameters\n",
    "alpha = 0.25\n",
    "numEpochs = 2**9\n",
    "snap = 2**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Schwarz tolerance, iteration variables, and random initial guess for u\n",
    "d_tol = 1e-3\n",
    "schwarz_conv = 1\n",
    "iterCount = 0\n",
    "u_i_minus1 = tf.constant(np.random.rand(N_r,1), shape=(N_r, 1), dtype=DTYPE)\n",
    "\n",
    "# Initialize variables for plotting Schwarz results\n",
    "x = tf.constant(np.linspace(0, 1, num=N_r), shape=(N_r, 1), dtype=DTYPE)\n",
    "u_true = pde1.f(x)\n",
    "fig = plt.figure()\n",
    "subplot_rows=0\n",
    "subplot_col=2\n",
    "fig_store = ()\n",
    "Schwarz_err = ()\n",
    "\n",
    "strong = 0\n",
    "# Main Schwarz loop\n",
    "while schwarz_conv > d_tol:\n",
    "    \n",
    "    # Update plot format with increasing iterations\n",
    "    if iterCount%subplot_col == 0:\n",
    "        subplot_rows+=1\n",
    "        gs = GridSpec(subplot_rows,subplot_col)\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            ax.set_position(gs[i].get_position(fig))\n",
    "            ax.set_subplotspec(gs[i])\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        fig.set_size_inches(3+subplot_rows*3, subplot_rows*3)\n",
    "    \n",
    "    ax = fig.add_subplot(subplot_rows,subplot_col,(iterCount%10 + 1))\n",
    "    ax.set_xlabel('x', fontsize=16)\n",
    "    ax.set_ylabel('u(x)', fontsize=16)\n",
    "    \n",
    "    iterCount += 1\n",
    "    ax.set_title('Schwarz iteration {:d}'.format(iterCount), fontsize=16)\n",
    "\n",
    "    ax.plot(x, u_true, 'k--')\n",
    "    \n",
    "    # intialize a new figure every 10 iterations to save new pages of results\n",
    "    if iterCount%10 == 0:\n",
    "        fig_store += (fig,)\n",
    "        fig = plt.figure()\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        subplot_rows=0\n",
    "        subplot_col=2 \n",
    "    \n",
    "    # initialize tuples to contain loss for each PINN and current approximation, u, for each PINN\n",
    "    loss_list = ()\n",
    "    u_i_om = ()\n",
    "\n",
    "    # Set batch size equal to number of points\n",
    "    batch_size = len(X_r)\n",
    "    \n",
    "    u_int = np.interp(x1_om[0], x_FD[:,0], u_FD)\n",
    "\n",
    "    # Initialize solver\n",
    "    p = FD_PINN_Schwarz_Steady(model_r, u_int, X_r, X_b, alpha, pde, strong, snap=snap, nu=nu, beta=beta)\n",
    "\n",
    "    # Solve PINN\n",
    "    p.solve(tf.keras.optimizers.Adam(learning_rate=lr), batch_size, numEpochs)\n",
    "\n",
    "    # Output loss results for each model\n",
    "    print('Model {:d}: '.format(1))\n",
    "    print('\\t'+'Residual loss = {:10.8e}'.format(p.phi_r))\n",
    "    print('\\t'+'Interface loss = {:10.8e}'.format(p.phi_i))\n",
    "    if not strong:\n",
    "        print('\\t'+'Boundary loss = {:10.8e}'.format(p.phi_b))\n",
    "    if snap:\n",
    "        print('\\t'+'Snapshot loss = {:10.8e}'.format(p.phi_s))\n",
    "    print('\\t'+'Total loss = {:10.8e}'.format(p.loss))\n",
    "    loss_list += (p.phi_r, p.phi_i, p.loss)\n",
    "    \n",
    "    f_NN = np.ones((A.shape[0], 1))\n",
    "    if strong:\n",
    "        #f_NN[0] += -d*p.BC_enforce(x_FD[0])*model_r(tf.reshape(x_FD[0], shape=(1,1))) - c*pde1.f(x_FD[1])\n",
    "        f_NN[0] += ( -d*p.BC_enforce(x_FD[0])*model_r(tf.reshape(x_FD[0], shape=(1,1))) \n",
    "                    - c*p.BC_enforce(x_FD[1])*model_r(tf.reshape(x_FD[1], shape=(1,1))) )\n",
    "            \n",
    "        #f_NN[1] += -d*pde1.f(x_FD[1]) \n",
    "        f_NN[1] += -d*p.BC_enforce(x_FD[1])*model_r(tf.reshape(x_FD[1], shape=(1,1))) \n",
    "    else:    \n",
    "        #f_NN[0] += -d*model_r(tf.reshape(x_FD[0], shape=(1,1))) - c*pde1.f(x_FD[1])\n",
    "        f_NN[0] += -d*model_r(tf.reshape(x_FD[0], shape=(1,1))) - c*model_r(tf.reshape(x_FD[1], shape=(1,1)))\n",
    "        \n",
    "        #f_NN[1] += -d*pde1.f(x_FD[1]) \n",
    "        f_NN[1] += -d*model_r(tf.reshape(x_FD[1], shape=(1,1)))\n",
    "    \n",
    "    u_FD = np.linalg.solve( A, f_NN )\n",
    "    u_FD = np.hstack((u_FD.flatten(), pde1.f(xr)))\n",
    "    u_int = np.interp(x1_om[0], x_FD[:,0], u_FD)\n",
    "\n",
    "    # Save current PINN approximations and add them to plot for current Schwarz iteration\n",
    "    if strong:\n",
    "        u_i_om = ( p.BC_enforce(X_om[0])*model_r(X_om[0]), tf.reshape(u_FD, shape = (len(u_FD), 1)) )\n",
    "    else:\n",
    "        u_i_om = ( model_r(X_om[0]), tf.reshape(u_FD, shape = (len(u_FD), 1)) )\n",
    "\n",
    "    ax.plot(X_om[0], u_i_om[0], x_FD, u_i_om[1])\n",
    "  \n",
    "    # Combine model approximations for each domain\n",
    "    u_i = sum(u_i_om)/len(u_i_om)\n",
    "\n",
    "    # Calculate the normalized difference between u for the current iteration and u for the previous iteration\n",
    "    schwarz_conv = tf.math.reduce_euclidean_norm(u_i - u_i_minus1)/tf.math.reduce_euclidean_norm(u_i)\n",
    "    \n",
    "    # Update u for the previous iteration\n",
    "    u_i_minus1 = u_i\n",
    "    \n",
    "    # Output current Schwarz error \n",
    "    print('\\nSchwarz iteration {:d}: error = {:10.8e}'.format(iterCount, schwarz_conv), \"\\n\")\n",
    "    \n",
    "    # Record loss and schwarz error history\n",
    "    #loss_frame.loc[iterCount-1] = loss_list\n",
    "    Schwarz_err += (schwarz_conv,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86995b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSpec(subplot_rows,subplot_col)\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.set_position(gs[i].get_position(fig))\n",
    "    ax.set_subplotspec(gs[i])\n",
    "fig.tight_layout(pad=1.0)\n",
    "fig.set_size_inches(3+subplot_rows*3, subplot_rows*3)\n",
    "\n",
    "# Save all figures as PDFs\n",
    "fig_store += (fig,)\n",
    "for i,figure in enumerate(fig_store):\n",
    "    figure.savefig(\"C:/Users/wdsnyde/code/fhnm-ldrd/Docs/Schwarz-PINNs/SchwarzIter_AdvecDiff_FD-PINN_Weak_nu_{:1.0e}_beta_{:1.0e}_pg{:d}.pdf\".format(nu,beta,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab478e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate internal points with gaussian distribution about the shock\n",
    "# mu = (nu/beta)*np.log( ( nu/beta )*( np.exp(beta/nu) - 1 ) )\n",
    "# sigma = (x1_om[-1] - x0_om[0])/1.5\n",
    "# x = stats.truncnorm((x0_om[0] - mu) / sigma, (x1_om[-1] - mu) / sigma, loc=mu, scale=sigma).rvs(N_r)\n",
    "\n",
    "# def get_curvature(x):\n",
    "#     u_x = (1/beta) - ( (beta/nu)*np.exp(beta*x/nu) )/( beta*(np.exp(beta/nu) - 1) )\n",
    "#     u_xx = -((beta/nu)**2)*np.exp(beta*x/nu)/( beta*(np.exp(beta/nu) - 1) )\n",
    "\n",
    "#     return np.abs(u_xx)/( (1 + u_x**2)**(3/2) )\n",
    "  \n",
    "# sample = 0\n",
    "# max_length = 1/(2**15)\n",
    "# max_curve_grad = 0.05\n",
    "# x = np.array([sample])\n",
    "\n",
    "# while sample < 1:\n",
    "#     sample_next = sample + max_length\n",
    "    \n",
    "#     k_diff = np.abs(get_curvature(sample) - get_curvature(sample_next))\n",
    "    \n",
    "#     if not k_diff > max_curve_grad:\n",
    "#         x = np.concatenate(( x, np.array([sample_next]) ), axis=0)\n",
    "#         sample = sample_next\n",
    "#         continue\n",
    "    \n",
    "#     sub_div = math.ceil(k_diff/max_curve_grad)\n",
    "    \n",
    "#     x = np.concatenate(( x, np.linspace(sample, sample_next, num=sub_div)[1:] ), axis=0)\n",
    "    \n",
    "#     sample = sample_next\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b075ec60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "602cefd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146e238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandia",
   "language": "python",
   "name": "sandia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
