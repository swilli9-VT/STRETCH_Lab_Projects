{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1b2ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .support_message_main_box {\n",
       "                position: relative;\n",
       "                display: table-cell;\n",
       "                vertical-align: middle;\n",
       "                width: 100%;\n",
       "                height: 8em;\n",
       "                padding: 1em;\n",
       "                padding-left: 11em;\n",
       "                background-color: #f7f7f7;\n",
       "                border: 1px solid #cfcfcf;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            .support_message_main_box img {\n",
       "                position: absolute;\n",
       "                height: 9em;\n",
       "                width: 9em;\n",
       "                left: 0.5em;\n",
       "                top: 0.5em;\n",
       "                border-radius: 1em;\n",
       "            }\n",
       "        </style>\n",
       "        <div class=\"support_message_main_box\">\n",
       "            <img src=\"https://avatars.githubusercontent.com/u/7738570?v=4\" />\n",
       "            <p>\n",
       "            <b>Hi!</b><br/>\n",
       "            <span>I am the author of\n",
       "            <a href=\"https://github.com/LucaCappelletti94/silence_tensorflow\" target=\"_blank\">\n",
       "                silence_tensorflow\n",
       "            </a>, which you use in this Notebook.\n",
       "            </span><br/>\n",
       "            \n",
       "        <span>I hope my work has saved you some time!</span><br/>\n",
       "        \n",
       "            <span>I love to code, but I also need coffee.</span>\n",
       "            <a href=\"https://github.com/sponsors/LucaCappelletti94\" target=\"_blank\">\n",
       "                Please sponsor me on GitHub ‚ù§Ô∏è\n",
       "            </a><br/>\n",
       "            <i>Good luck in your coding üçÄ!</i>\n",
       "            <br/>\n",
       "            <i>- Luca</i>\n",
       "            </p>\n",
       "        <div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from decimal import *\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sobol\n",
    "import nbimporter\n",
    "from PINN_Solver_Classes import *\n",
    "from PDE_Classes import *\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "# from keras import callbacks\n",
    "# import time\n",
    "# import itertools as product\n",
    "\n",
    "# Set data type\n",
    "DTYPE = 'float64'\n",
    "tf.keras.backend.set_floatx(DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c55f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_b = 2**8 # number of boundary and interface points\n",
    "N_r = 2**10 # number of internal collocation points\n",
    "\n",
    "# Declare PDE parameters\n",
    "nu = 0.001\n",
    "beta = 1\n",
    "\n",
    "if nu <= 2e-3:\n",
    "    mu = np.log(( (nu/beta)**(nu/beta) )*(np.exp(1)))\n",
    "else:\n",
    "    mu = (nu/beta)*np.log( ( nu/beta )*( np.exp(beta/nu) - 1 ) )\n",
    "\n",
    "# Declare bounds of each subdomain\n",
    "sub = (\n",
    "      [0, 0.6],\n",
    "      [0.5, 0.85],\n",
    "      [0.75, mu+0.002],\n",
    "      [mu, 1]\n",
    "#      [0.95, 0.99],\n",
    "#      [0.98, 1]\n",
    "     )\n",
    "\n",
    "# Initialize list of points which lie on the boundary\n",
    "BC = [0, 1]\n",
    "\n",
    "# Lower bounds as TF scalars \n",
    "x0_om = tf.constant([x[0] for x in sub], dtype=DTYPE)\n",
    "# Upper bounds as TF scalars \n",
    "x1_om = tf.constant([x[1] for x in sub], dtype=DTYPE)\n",
    "\n",
    "# Generate boundary points for each subdomain boundary\n",
    "# zipped booleans indicate whether a point is a model or interface boundary\n",
    "X_b_om = [ tuple( zip( [tf.constant(np.repeat([[i]], N_b, axis=0), dtype=DTYPE) for i in sub[j]], [k in BC for k in sub[j]] ) ) \n",
    "          for j in range(len(sub)) ]\n",
    "\n",
    "# Declare PDE first as a class for the PINN solver to inherit\n",
    "pde = PDE_1D_Steady_AdvecDiff\n",
    "\n",
    "# Then declare an instance of the PDE class to use in the Driver\n",
    "pde1 = pde(nu=nu, beta=beta)\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Generate uniform internal points for the whole domain\n",
    "points = sobol.sample(dimension=1, n_points=N_r-2)\n",
    "xwidth = BC[1] - BC[0]\n",
    "x_uni = np.vstack( (np.vstack( ([0], xwidth*points + BC[0]) ), [1]) )\n",
    "\n",
    "# Generate internal points with gaussian distribution centered at the shock\n",
    "sigma = (x1_om[-1] - x0_om[0])/2\n",
    "x_gauss = np.array(stats.truncnorm((x0_om[0] - mu) / sigma, (x1_om[-1] - mu) / sigma, loc=mu, scale=sigma).rvs(N_r))\n",
    "\n",
    "# Take as the final sample set the union of the two sets defined above\n",
    "x = np.union1d(x_uni, x_gauss)\n",
    "\n",
    "# Store internal points as tensor object\n",
    "X_r = tf.constant(x, shape=(len(x), 1), dtype=DTYPE)\n",
    "\n",
    "# Split internal points by subdomain and store in tuple\n",
    "X_r_om = ()\n",
    "for i in range(len(x0_om)):\n",
    "    mask = (X_r >= x0_om[i]) & (X_r <= x1_om[i])\n",
    "    temp = tf.boolean_mask(X_r, mask)\n",
    "    X_r_om += ( tf.constant(temp, shape=(temp.shape[0],1), dtype=DTYPE), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f366773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "# m = 1\n",
    "# ax.plot(x, np.tanh( m*(1-x) )*np.tanh( x ), 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68de015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network to handle each domain and intialize data frame for loss\n",
    "column_list = []\n",
    "model_om = ()\n",
    "for i in range(len(sub)):\n",
    "    model_om += ( PINN_Architecture(x0_om[i], x1_om[i]), )\n",
    "    model_om[i].build(input_shape=(None, X_r_om[i].shape[1]))\n",
    "    column_list += [\"model {:d} Phi_r\".format(i+1), \n",
    "                    \"model {:d} Phi_i\".format(i+1), \"model {:d} Loss\".format(i+1)]\n",
    "\n",
    "loss_frame = pd.DataFrame(columns=column_list)\n",
    "\n",
    "# Initialize Schwarz tolerance, iteration variables, and random initial guess for u\n",
    "d_tol = 1e-5\n",
    "schwarz_conv = 1\n",
    "iterCount = 0\n",
    "u_i_minus1 = tf.constant(np.random.rand(N_r,1), shape=(N_r, 1), dtype=DTYPE)\n",
    "\n",
    "# Define learning rate schedule and choose optimizer (Adam)\n",
    "lr = 1e-3#tf.keras.optimizers.schedules.PiecewiseConstantDecay([2**6, 2**7],[1e-2,5e-3,1e-3])\n",
    "\n",
    "# Declare hyperparameters\n",
    "alpha = 0.2\n",
    "numEpochs = 2**9\n",
    "snap = 2**7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for plotting Schwarz results\n",
    "x = tf.constant(np.linspace(0, 1, num=N_r), shape=(N_r, 1), dtype=DTYPE)\n",
    "x_om = [tf.constant(np.linspace(s[0], s[1], num=N_r), shape=(N_r, 1), dtype=DTYPE) for s in sub]\n",
    "u_true = pde1.f(x)\n",
    "fig = plt.figure()\n",
    "subplot_rows=0\n",
    "subplot_col=2\n",
    "fig_store = ()\n",
    "Schwarz_err = ()\n",
    "\n",
    "# Main Schwarz loop\n",
    "while schwarz_conv > d_tol:\n",
    "    \n",
    "    # Update plot format with increasing iterations\n",
    "    if iterCount%subplot_col == 0:\n",
    "        subplot_rows+=1\n",
    "        gs = GridSpec(subplot_rows,subplot_col)\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            ax.set_position(gs[i].get_position(fig))\n",
    "            ax.set_subplotspec(gs[i])\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        fig.set_size_inches(3+subplot_rows*3, subplot_rows*3)\n",
    "    \n",
    "    ax = fig.add_subplot(subplot_rows,subplot_col,(iterCount%10 + 1))\n",
    "    ax.set_xlabel('x', fontsize=16)\n",
    "    ax.set_ylabel('u(x)', fontsize=16)\n",
    "    \n",
    "    iterCount += 1\n",
    "    ax.set_title('Schwarz iteration {:d}'.format(iterCount), fontsize=16)\n",
    "\n",
    "    ax.plot(x, u_true, 'k--')\n",
    "    \n",
    "    # intialize a new figure every 10 iterations to save new pages of results\n",
    "    if iterCount%10 == 0:\n",
    "        fig_store += (fig,)\n",
    "        fig = plt.figure()\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        subplot_rows=0\n",
    "        subplot_col=2 \n",
    "    \n",
    "    # initialize tuples to contain loss for each PINN and current approximation, u, for each PINN\n",
    "    loss_list = ()\n",
    "    u_i_om = ()\n",
    "    \n",
    "    # loop over each model for training\n",
    "    for s in range(len(model_om)):\n",
    "        \n",
    "        # Current model\n",
    "        model_r = model_om[s]\n",
    "        # Adjacent models for interface conditions\n",
    "        model_i = model_om[s-1:s] + model_om[s+1:s+2]\n",
    "        \n",
    "        # Current model domain points\n",
    "        X_r = X_r_om[s]\n",
    "        # Current model boundary points\n",
    "        X_b = X_b_om[s]\n",
    "        \n",
    "        # Set batch size equal to number of points\n",
    "        batch_size = len(X_r)\n",
    "\n",
    "        # Initialize solver\n",
    "        pSDBC = PINN_SDBC_Schwarz_Steady(model_r, model_i, X_r, X_b, alpha, pde, snap=snap, nu=nu, beta=beta)\n",
    "\n",
    "        # Solve PINN\n",
    "        pSDBC.solve(tf.keras.optimizers.Adam(learning_rate=lr), batch_size, numEpochs)\n",
    "        \n",
    "        # Output loss results for each model\n",
    "        print('Model {:d}: '.format(s+1))\n",
    "        print('\\t'+'Residual loss = {:10.8e}'.format(pSDBC.phi_r))\n",
    "        print('\\t'+'Interface loss = {:10.8e}'.format(pSDBC.phi_i))\n",
    "        if snap:\n",
    "            print('\\t'+'Snapshot loss = {:10.8e}'.format(pSDBC.phi_s))\n",
    "        print('\\t'+'Total loss = {:10.8e}'.format(pSDBC.loss))\n",
    "        loss_list += (pSDBC.phi_r, pSDBC.phi_i, pSDBC.loss)\n",
    "        \n",
    "        # Save current PINN approximations and add them to plot for current Schwarz iteration\n",
    "        u_i_om += ( pSDBC.BC_enforce(x_om[s])*model_r(x_om[s]), )\n",
    "        ax.plot(x_om[s], u_i_om[s])\n",
    "        \n",
    "    # Combine model approximations for each domain\n",
    "    u_i = sum(u_i_om)/len(u_i_om)\n",
    "\n",
    "    # Calculate the normalized difference between u for the current iteration and u for the previous iteration\n",
    "    schwarz_conv = tf.math.reduce_euclidean_norm(u_i - u_i_minus1)/tf.math.reduce_euclidean_norm(u_i)\n",
    "    \n",
    "    # Update u for the previous iteration\n",
    "    u_i_minus1 = u_i\n",
    "    \n",
    "    # Output current Schwarz error \n",
    "    print('\\nSchwarz iteration {:d}: error = {:10.8e}'.format(iterCount, schwarz_conv), \"\\n\")\n",
    "    \n",
    "    # Record loss and schwarz error history\n",
    "    loss_frame.loc[iterCount-1] = loss_list\n",
    "    Schwarz_err += (schwarz_conv,)\n",
    "\n",
    "\n",
    "\n",
    "gs = GridSpec(subplot_rows,subplot_col)\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.set_position(gs[i].get_position(fig))\n",
    "    ax.set_subplotspec(gs[i])\n",
    "fig.tight_layout(pad=1.0)\n",
    "fig.set_size_inches(3+subplot_rows*3, subplot_rows*3)\n",
    "# Save all figures as PDFs\n",
    "fig_store += (fig,)\n",
    "for i,figure in enumerate(fig_store):\n",
    "    figure.savefig(\"C:/Users/wdsnyde/code/fhnm-ldrd/Docs/Schwarz-PINNs/SchwarzIter_AdvecDiff_SDBC_nu_{:1.0e}_beta_{:1.0e}_pg{:d}.pdf\".format(nu,beta,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86995b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_store += (fig,)\n",
    "# for i,figure in enumerate(fig_store):\n",
    "#     figure.savefig(\"C:/Users/wdsnyde/code/fhnm-ldrd/Docs/Schwarz-PINNs/SchwarzIter_AdvecDiff_SDBC_nu_{:1.0e}_beta_{:1.0e}_pg{:d}.pdf\".format(nu,beta,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab478e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate internal points with gaussian distribution about the shock\n",
    "# mu = (nu/beta)*np.log( ( nu/beta )*( np.exp(beta/nu) - 1 ) )\n",
    "# sigma = (x1_om[-1] - x0_om[0])/1.5\n",
    "# x = stats.truncnorm((x0_om[0] - mu) / sigma, (x1_om[-1] - mu) / sigma, loc=mu, scale=sigma).rvs(N_r)\n",
    "\n",
    "# def get_curvature(x):\n",
    "#     u_x = (1/beta) - ( (beta/nu)*np.exp(beta*x/nu) )/( beta*(np.exp(beta/nu) - 1) )\n",
    "#     u_xx = -((beta/nu)**2)*np.exp(beta*x/nu)/( beta*(np.exp(beta/nu) - 1) )\n",
    "\n",
    "#     return np.abs(u_xx)/( (1 + u_x**2)**(3/2) )\n",
    "  \n",
    "# sample = 0\n",
    "# max_length = 1/(2**15)\n",
    "# max_curve_grad = 0.05\n",
    "# x = np.array([sample])\n",
    "\n",
    "# while sample < 1:\n",
    "#     sample_next = sample + max_length\n",
    "    \n",
    "#     k_diff = np.abs(get_curvature(sample) - get_curvature(sample_next))\n",
    "    \n",
    "#     if not k_diff > max_curve_grad:\n",
    "#         x = np.concatenate(( x, np.array([sample_next]) ), axis=0)\n",
    "#         sample = sample_next\n",
    "#         continue\n",
    "    \n",
    "#     sub_div = math.ceil(k_diff/max_curve_grad)\n",
    "    \n",
    "#     x = np.concatenate(( x, np.linspace(sample, sample_next, num=sub_div)[1:] ), axis=0)\n",
    "    \n",
    "#     sample = sample_next\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b075ec60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cefd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146e238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ROM_ML] *",
   "language": "python",
   "name": "conda-env-ROM_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
